{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimize_play_gradescent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKGMlnaZEcYUeYaAPy1gyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aasem/cvisionmcs/blob/main/optimize_play_gradescent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4kgUwBthkRl"
      },
      "source": [
        "# Optimization Strategies - Linear Classification (SVM and Softmax) for CIFAR10 Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsX3mZLlZO9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282bd35b-8f7b-4073-860c-a132f2dec1e2"
      },
      "source": [
        "!git clone https://github.com/aasem/cvisionmcs\n",
        "# Definitions\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "# sys.path.append('/content/cvisionmcs')\n",
        "from cvisionmcs import data_utils\n",
        "from cvisionmcs import download\n",
        "\n",
        "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "download_dir = \"./data\"\n",
        "download.maybe_download_and_extract(url,download_dir)\n",
        "\n",
        "cifar10_dir = './data/cifar-10-batches-py'\n",
        "X_train, y_train, X_test, y_test = data_utils.load_CIFAR10(cifar10_dir)\n",
        "\n",
        "# reshaping data and placing into rows\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "# append 1 in the last column to cater for bias and transform into columns\n",
        "X_train = np.append(X_train, np.ones((X_train.shape[0],1)), axis=1)\n",
        "X_test = np.append(X_test, np.ones((X_test.shape[0],1)), axis=1)\n",
        "X_train = np.transpose(X_train)\n",
        "X_test = np.transpose(X_test)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cvisionmcs'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 146 (delta 45), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 3.44 MiB | 13.04 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "- Download progress: 100.0%\n",
            "Download finished. Extracting files.\n",
            "Done.\n",
            "(3073, 50000) (3073, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBakDXDzd8Pd"
      },
      "source": [
        "def loss_svm(W, X, y, r_lambda):\n",
        "    \"\"\"\n",
        "    Compute the SVM loss.\n",
        "    \n",
        "    Input Parameters\n",
        "    ----------\n",
        "    W: (K, D+1) array of weights, K is the number of classes and D is the dimension of one sample plus bias\n",
        "    X: (D+1, N) array of training data, each column is a training sample with D-dimension plus bias\n",
        "    y: (N, ) 1-dimension array of target data with length N with lables 0,1, ... K-1, for K classes\n",
        "    r_lambda: (float) regularization strength for optimization.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    loss: (float)\n",
        "    \"\"\"\n",
        "    \n",
        "    # initialization\n",
        "    loss = 0.0\n",
        "    delta = 1.0\n",
        "    N = y.shape[0]\n",
        "\n",
        "    # compute all scores s_j\n",
        "    scores = W.dot(X) # [K x N] matrix\n",
        " \n",
        "    # get the true class score \n",
        "    true_class_score = scores[y, range(N)] # [1 x N]\n",
        "    \n",
        "    margins = scores - true_class_score + delta # [K x N]\n",
        "\n",
        "    # threshold the margins to max(0, -)\n",
        "    margins = np.maximum(0, margins)\n",
        "    margins[y, range(N)] = 0 # neglect the true class scores\n",
        "\n",
        "    loss = np.sum(margins) / N\n",
        "\n",
        "    # add regularization to loss\n",
        "    loss += 0.5 * r_lambda * np.sum(W * W)\n",
        "   \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_TJ1dQDXiJx"
      },
      "source": [
        "## Exploring Optmization Strategies\n",
        "**Strategy #1: Random Search (Worst Idea)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZBqbV8qYNkT",
        "outputId": "7cfa9e19-2930-439d-b202-c67f621acdff"
      },
      "source": [
        "bestloss = float('inf') # Python assigns the highest possible float value\n",
        "for num in range(50):\n",
        "  W = np.random.randn(10, X_train.shape[0]) * 0.001 # generate random parameters\n",
        "  loss = loss_svm(W, X_train, y_train, 0.0001) # get the loss over the entire training set\n",
        "  # keep track of the best solution\n",
        "  if loss < bestloss:\n",
        "    bestloss = loss\n",
        "    bestW = W\n",
        "  print('in attempt %d the loss was %f, best %f' % (num, loss, bestloss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in attempt 0 the loss was 46.928716, best 46.928716\n",
            "in attempt 1 the loss was 38.640431, best 38.640431\n",
            "in attempt 2 the loss was 40.182537, best 38.640431\n",
            "in attempt 3 the loss was 56.392473, best 38.640431\n",
            "in attempt 4 the loss was 35.419734, best 35.419734\n",
            "in attempt 5 the loss was 48.367726, best 35.419734\n",
            "in attempt 6 the loss was 55.817676, best 35.419734\n",
            "in attempt 7 the loss was 35.279948, best 35.279948\n",
            "in attempt 8 the loss was 35.848635, best 35.279948\n",
            "in attempt 9 the loss was 29.905317, best 29.905317\n",
            "in attempt 10 the loss was 30.880710, best 29.905317\n",
            "in attempt 11 the loss was 33.170036, best 29.905317\n",
            "in attempt 12 the loss was 30.681584, best 29.905317\n",
            "in attempt 13 the loss was 49.819731, best 29.905317\n",
            "in attempt 14 the loss was 52.012972, best 29.905317\n",
            "in attempt 15 the loss was 43.894445, best 29.905317\n",
            "in attempt 16 the loss was 43.145589, best 29.905317\n",
            "in attempt 17 the loss was 43.973533, best 29.905317\n",
            "in attempt 18 the loss was 37.758166, best 29.905317\n",
            "in attempt 19 the loss was 39.703681, best 29.905317\n",
            "in attempt 20 the loss was 44.256951, best 29.905317\n",
            "in attempt 21 the loss was 56.073572, best 29.905317\n",
            "in attempt 22 the loss was 39.329674, best 29.905317\n",
            "in attempt 23 the loss was 40.670263, best 29.905317\n",
            "in attempt 24 the loss was 49.080175, best 29.905317\n",
            "in attempt 25 the loss was 47.699609, best 29.905317\n",
            "in attempt 26 the loss was 44.282504, best 29.905317\n",
            "in attempt 27 the loss was 58.283445, best 29.905317\n",
            "in attempt 28 the loss was 46.222833, best 29.905317\n",
            "in attempt 29 the loss was 43.163662, best 29.905317\n",
            "in attempt 30 the loss was 31.918584, best 29.905317\n",
            "in attempt 31 the loss was 37.372882, best 29.905317\n",
            "in attempt 32 the loss was 38.020309, best 29.905317\n",
            "in attempt 33 the loss was 38.916397, best 29.905317\n",
            "in attempt 34 the loss was 37.287292, best 29.905317\n",
            "in attempt 35 the loss was 38.029455, best 29.905317\n",
            "in attempt 36 the loss was 39.532503, best 29.905317\n",
            "in attempt 37 the loss was 33.335941, best 29.905317\n",
            "in attempt 38 the loss was 37.678567, best 29.905317\n",
            "in attempt 39 the loss was 53.643832, best 29.905317\n",
            "in attempt 40 the loss was 42.802406, best 29.905317\n",
            "in attempt 41 the loss was 57.403409, best 29.905317\n",
            "in attempt 42 the loss was 52.924641, best 29.905317\n",
            "in attempt 43 the loss was 54.843506, best 29.905317\n",
            "in attempt 44 the loss was 55.827680, best 29.905317\n",
            "in attempt 45 the loss was 55.895014, best 29.905317\n",
            "in attempt 46 the loss was 44.673012, best 29.905317\n",
            "in attempt 47 the loss was 36.029052, best 29.905317\n",
            "in attempt 48 the loss was 41.286852, best 29.905317\n",
            "in attempt 49 the loss was 38.232445, best 29.905317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuf9SO00flEO",
        "outputId": "2dfb4d65-36c8-4ce7-e852-1bdac74648ea"
      },
      "source": [
        "# compute scores with best W\n",
        "scores = bestW.dot(X_test) # 10 x 10000, the class scores for all test examples\n",
        "# index with max score in each column (the predicted class)\n",
        "y_pred = np.argmax(scores, axis = 0)\n",
        "# calculate accuracy (fraction of correct predictions)\n",
        "acc = np.mean(y_pred == y_test) * 100\n",
        "print('Accuracy of classification is %f' % acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of classification is 9.840000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKOUTsZnh_9S"
      },
      "source": [
        "**Strategy #2: Random Local Search (Bad Idea)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BGLM7B9iwZJ",
        "outputId": "4ddb44cf-66de-4922-fb95-82b3138aa143"
      },
      "source": [
        "W = np.random.randn(10, X_train.shape[0]) * 0.001 # generate random parameters\n",
        "bestloss = float('inf') # Python assigns the highest possible float value\n",
        "for num in range(100):\n",
        "  step_size = 0.0001\n",
        "  Wtry = W + np.random.randn(10, X_train.shape[0]) * step_size\n",
        "  loss = loss_svm(Wtry, X_train, y_train, 0.0001) # get the loss over the entire training set\n",
        "  # keep track of the best solution\n",
        "  if loss < bestloss:\n",
        "    bestloss = loss\n",
        "    bestW = Wtry\n",
        "  print('in attempt %d the loss was %f, best %f' % (num, loss, bestloss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in attempt 0 the loss was 47.746675, best 47.746675\n",
            "in attempt 1 the loss was 46.478478, best 46.478478\n",
            "in attempt 2 the loss was 44.014832, best 44.014832\n",
            "in attempt 3 the loss was 46.827791, best 44.014832\n",
            "in attempt 4 the loss was 47.656779, best 44.014832\n",
            "in attempt 5 the loss was 48.373235, best 44.014832\n",
            "in attempt 6 the loss was 46.005367, best 44.014832\n",
            "in attempt 7 the loss was 47.773845, best 44.014832\n",
            "in attempt 8 the loss was 45.743818, best 44.014832\n",
            "in attempt 9 the loss was 47.419827, best 44.014832\n",
            "in attempt 10 the loss was 46.328564, best 44.014832\n",
            "in attempt 11 the loss was 45.408932, best 44.014832\n",
            "in attempt 12 the loss was 46.508768, best 44.014832\n",
            "in attempt 13 the loss was 46.301365, best 44.014832\n",
            "in attempt 14 the loss was 48.620399, best 44.014832\n",
            "in attempt 15 the loss was 46.285654, best 44.014832\n",
            "in attempt 16 the loss was 46.012155, best 44.014832\n",
            "in attempt 17 the loss was 46.942581, best 44.014832\n",
            "in attempt 18 the loss was 46.484501, best 44.014832\n",
            "in attempt 19 the loss was 47.075739, best 44.014832\n",
            "in attempt 20 the loss was 45.324535, best 44.014832\n",
            "in attempt 21 the loss was 47.224762, best 44.014832\n",
            "in attempt 22 the loss was 46.655275, best 44.014832\n",
            "in attempt 23 the loss was 48.465677, best 44.014832\n",
            "in attempt 24 the loss was 46.899517, best 44.014832\n",
            "in attempt 25 the loss was 48.227560, best 44.014832\n",
            "in attempt 26 the loss was 45.357075, best 44.014832\n",
            "in attempt 27 the loss was 46.321857, best 44.014832\n",
            "in attempt 28 the loss was 46.635299, best 44.014832\n",
            "in attempt 29 the loss was 47.653481, best 44.014832\n",
            "in attempt 30 the loss was 47.960408, best 44.014832\n",
            "in attempt 31 the loss was 47.495118, best 44.014832\n",
            "in attempt 32 the loss was 45.294309, best 44.014832\n",
            "in attempt 33 the loss was 48.189714, best 44.014832\n",
            "in attempt 34 the loss was 45.222836, best 44.014832\n",
            "in attempt 35 the loss was 46.404730, best 44.014832\n",
            "in attempt 36 the loss was 46.082638, best 44.014832\n",
            "in attempt 37 the loss was 45.314834, best 44.014832\n",
            "in attempt 38 the loss was 47.329577, best 44.014832\n",
            "in attempt 39 the loss was 48.118876, best 44.014832\n",
            "in attempt 40 the loss was 43.731681, best 43.731681\n",
            "in attempt 41 the loss was 45.850910, best 43.731681\n",
            "in attempt 42 the loss was 46.224816, best 43.731681\n",
            "in attempt 43 the loss was 45.236261, best 43.731681\n",
            "in attempt 44 the loss was 46.187476, best 43.731681\n",
            "in attempt 45 the loss was 46.228187, best 43.731681\n",
            "in attempt 46 the loss was 46.652078, best 43.731681\n",
            "in attempt 47 the loss was 48.288363, best 43.731681\n",
            "in attempt 48 the loss was 45.949546, best 43.731681\n",
            "in attempt 49 the loss was 46.282318, best 43.731681\n",
            "in attempt 50 the loss was 48.741176, best 43.731681\n",
            "in attempt 51 the loss was 46.433626, best 43.731681\n",
            "in attempt 52 the loss was 45.337121, best 43.731681\n",
            "in attempt 53 the loss was 46.179255, best 43.731681\n",
            "in attempt 54 the loss was 45.027106, best 43.731681\n",
            "in attempt 55 the loss was 46.830455, best 43.731681\n",
            "in attempt 56 the loss was 47.922536, best 43.731681\n",
            "in attempt 57 the loss was 47.500152, best 43.731681\n",
            "in attempt 58 the loss was 45.394822, best 43.731681\n",
            "in attempt 59 the loss was 47.902110, best 43.731681\n",
            "in attempt 60 the loss was 45.599388, best 43.731681\n",
            "in attempt 61 the loss was 45.226667, best 43.731681\n",
            "in attempt 62 the loss was 46.197650, best 43.731681\n",
            "in attempt 63 the loss was 44.993718, best 43.731681\n",
            "in attempt 64 the loss was 44.465129, best 43.731681\n",
            "in attempt 65 the loss was 46.031694, best 43.731681\n",
            "in attempt 66 the loss was 45.876431, best 43.731681\n",
            "in attempt 67 the loss was 46.432806, best 43.731681\n",
            "in attempt 68 the loss was 42.822287, best 42.822287\n",
            "in attempt 69 the loss was 46.429641, best 42.822287\n",
            "in attempt 70 the loss was 46.725945, best 42.822287\n",
            "in attempt 71 the loss was 45.064637, best 42.822287\n",
            "in attempt 72 the loss was 45.900029, best 42.822287\n",
            "in attempt 73 the loss was 45.304412, best 42.822287\n",
            "in attempt 74 the loss was 47.330752, best 42.822287\n",
            "in attempt 75 the loss was 47.814634, best 42.822287\n",
            "in attempt 76 the loss was 47.323860, best 42.822287\n",
            "in attempt 77 the loss was 43.234611, best 42.822287\n",
            "in attempt 78 the loss was 45.899594, best 42.822287\n",
            "in attempt 79 the loss was 46.145439, best 42.822287\n",
            "in attempt 80 the loss was 46.579434, best 42.822287\n",
            "in attempt 81 the loss was 43.827226, best 42.822287\n",
            "in attempt 82 the loss was 45.163320, best 42.822287\n",
            "in attempt 83 the loss was 44.312385, best 42.822287\n",
            "in attempt 84 the loss was 46.769137, best 42.822287\n",
            "in attempt 85 the loss was 48.366580, best 42.822287\n",
            "in attempt 86 the loss was 45.277295, best 42.822287\n",
            "in attempt 87 the loss was 45.582458, best 42.822287\n",
            "in attempt 88 the loss was 47.752135, best 42.822287\n",
            "in attempt 89 the loss was 44.727401, best 42.822287\n",
            "in attempt 90 the loss was 44.517286, best 42.822287\n",
            "in attempt 91 the loss was 44.237556, best 42.822287\n",
            "in attempt 92 the loss was 47.342394, best 42.822287\n",
            "in attempt 93 the loss was 48.292048, best 42.822287\n",
            "in attempt 94 the loss was 46.130131, best 42.822287\n",
            "in attempt 95 the loss was 46.697632, best 42.822287\n",
            "in attempt 96 the loss was 48.244079, best 42.822287\n",
            "in attempt 97 the loss was 48.025341, best 42.822287\n",
            "in attempt 98 the loss was 47.129811, best 42.822287\n",
            "in attempt 99 the loss was 47.310947, best 42.822287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y84ff2i3j8oS",
        "outputId": "bd4147a6-e77c-4823-f0cb-b06ad5db8ab9"
      },
      "source": [
        "# compute scores with best W\n",
        "scores = bestW.dot(X_test) # 10 x 10000, the class scores for all test examples\n",
        "# index with max score in each column (the predicted class)\n",
        "y_pred = np.argmax(scores, axis = 0)\n",
        "# calculate accuracy (fraction of correct predictions)\n",
        "acc = np.mean(y_pred == y_test) * 100\n",
        "print('Accuracy of classification is %f' % acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of classification is 9.070000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD7PCPCtnwQP"
      },
      "source": [
        "**Strategy #3: Follow the Slope**\n",
        "\n",
        "**Simple Example of Analytical Computation of the Gradient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b65rV4mA4J0t"
      },
      "source": [
        "1.  Plotting the loss function $L(w)=w^2$ at some values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Vx83KbcisCJj",
        "outputId": "aacbea51-280e-4e6d-a5e5-b139c0e7ddaa"
      },
      "source": [
        "# plot of simple function\n",
        "from numpy import arange\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# loss function L\n",
        "def loss_fn(w):\n",
        "\treturn w**2.0\n",
        " \n",
        "# define range for input\n",
        "w_min, w_max = -6.0, 6.0\n",
        "weights = arange(w_min, w_max+0.1, 0.1)\n",
        "\n",
        "# compute values of loss function at given weights\n",
        "loss_values = loss_fn(weights)\n",
        "\n",
        "# create a line plot of weights vs loss\n",
        "pyplot.plot(weights, loss_values)\n",
        "pyplot.xlabel('weights')\n",
        "pyplot.ylabel('loss')\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5AiQWTI4SO_"
      },
      "source": [
        "2.  Implementing Gradient Descent Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8kwYPcW3AUn",
        "outputId": "5055d58d-897e-4f0d-800c-956ef07f058a"
      },
      "source": [
        "# loss function L\n",
        "def loss_fn(w):\n",
        "\treturn w**2.0\n",
        "\n",
        "# the gradient function delta\n",
        "def eval_delta_fn(w):\n",
        "\treturn w * 2.0\n",
        "\n",
        "# gradient descent algorithm\n",
        "def gradient_descent(loss_fn, eval_delta_fn, n_iter, step_size):\n",
        "\t# generate an initial point\n",
        "\tweights = 3\n",
        " \t# run the gradient descent\n",
        "\tfor i in range(n_iter):\n",
        "\t\t# calculate gradient\n",
        "\t\tgradient = eval_delta_fn(weights)\n",
        "\t\t# take a step\n",
        "\t\tweights = weights - step_size * gradient\n",
        "\t\t# evaluate loss at candidate weight\n",
        "\t\tweights_eval = loss_fn(weights)\n",
        "\t\t# report progress\n",
        "\t\tprint('>%d L(%s) = %.5f' % (i, weights, weights_eval))\n",
        "\treturn [weights, weights_eval]\n",
        " \n",
        "# define range for input\n",
        "bounds = np.asarray([[-6.0, 6.0]])\n",
        "# define the total iterations\n",
        "n_iter = 35\n",
        "# define the step size\n",
        "step_size = 0.1\n",
        "# perform the gradient descent search\n",
        "bestW, loss_bestW = gradient_descent(loss_fn, eval_delta_fn, n_iter, step_size)\n",
        "print('Done!')\n",
        "print('L(%s) = %f' % (bestW, loss_bestW))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">0 L(2.4) = 5.76000\n",
            ">1 L(1.92) = 3.68640\n",
            ">2 L(1.536) = 2.35930\n",
            ">3 L(1.2288000000000001) = 1.50995\n",
            ">4 L(0.9830400000000001) = 0.96637\n",
            ">5 L(0.7864320000000001) = 0.61848\n",
            ">6 L(0.6291456000000001) = 0.39582\n",
            ">7 L(0.5033164800000001) = 0.25333\n",
            ">8 L(0.40265318400000005) = 0.16213\n",
            ">9 L(0.32212254720000005) = 0.10376\n",
            ">10 L(0.25769803776000005) = 0.06641\n",
            ">11 L(0.20615843020800004) = 0.04250\n",
            ">12 L(0.16492674416640002) = 0.02720\n",
            ">13 L(0.13194139533312002) = 0.01741\n",
            ">14 L(0.10555311626649602) = 0.01114\n",
            ">15 L(0.08444249301319681) = 0.00713\n",
            ">16 L(0.06755399441055746) = 0.00456\n",
            ">17 L(0.05404319552844596) = 0.00292\n",
            ">18 L(0.04323455642275677) = 0.00187\n",
            ">19 L(0.03458764513820541) = 0.00120\n",
            ">20 L(0.02767011611056433) = 0.00077\n",
            ">21 L(0.022136092888451465) = 0.00049\n",
            ">22 L(0.017708874310761173) = 0.00031\n",
            ">23 L(0.014167099448608939) = 0.00020\n",
            ">24 L(0.011333679558887151) = 0.00013\n",
            ">25 L(0.009066943647109721) = 0.00008\n",
            ">26 L(0.007253554917687777) = 0.00005\n",
            ">27 L(0.005802843934150222) = 0.00003\n",
            ">28 L(0.004642275147320177) = 0.00002\n",
            ">29 L(0.003713820117856142) = 0.00001\n",
            ">30 L(0.0029710560942849138) = 0.00001\n",
            ">31 L(0.002376844875427931) = 0.00001\n",
            ">32 L(0.0019014759003423449) = 0.00000\n",
            ">33 L(0.001521180720273876) = 0.00000\n",
            ">34 L(0.0012169445762191008) = 0.00000\n",
            "Done!\n",
            "L(0.0012169445762191008) = 0.000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWWTmwjG9Q0d"
      },
      "source": [
        "3.  Explore the learning rate (step size)\n",
        "\n",
        "**See effects of various learning rates especially very small (1e-5) and very big (1.0)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru9NQShr-1Eh"
      },
      "source": [
        "4.  We can store all the weights and loss computed at those weights to visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "IFB-rPH-9bmN",
        "outputId": "d5acef4b-256f-498c-8d01-84dc951b8b08"
      },
      "source": [
        "# loss function L\n",
        "def loss_fn(w):\n",
        "\treturn w**2.0\n",
        "\n",
        "# the gradient function delta\n",
        "def eval_delta_fn(w):\n",
        "\treturn w * 2.0\n",
        "\n",
        "# gradient descent algorithm\n",
        "def gradient_descent(loss_fn, eval_delta_fn, bounds, n_iter, step_size):\n",
        "  # track all solutions\n",
        "\tweights_list, weights_eval_list = list(), list()\n",
        "\t# generate an initial point\n",
        "\tweights = -5\n",
        "  # bounds[:, 0] + np.random.rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
        "\t# run the gradient descent\n",
        "\tfor i in range(n_iter):\n",
        "\t\t# calculate gradient\n",
        "\t\tgradient = eval_delta_fn(weights)\n",
        "\t\t# take a step\n",
        "\t\tweights = weights - step_size * gradient\n",
        "\t\t# evaluate loss at candidate weight\n",
        "\t\tweights_eval = loss_fn(weights)\n",
        "    # store solution\n",
        "\t\tweights_list.append(weights)\n",
        "\t\tweights_eval_list.append(weights_eval)\n",
        "\t\t# report progress\n",
        "\t\tprint('>%d L(%s) = %.5f' % (i, weights, weights_eval))\n",
        "\treturn [weights_list, weights_eval_list]\n",
        " \n",
        "# define range for input\n",
        "bounds = np.asarray([[-6.0, 6.0]])\n",
        "# define the total iterations\n",
        "n_iter = 35\n",
        "# define the step size\n",
        "step_size = 0.1\n",
        "# perform the gradient descent search\n",
        "weights_list, weights_eval_list = gradient_descent(loss_fn, eval_delta_fn, bounds, n_iter, step_size)\n",
        "\n",
        "# sample input range uniformly at 0.1 increments\n",
        "input_w = arange(bounds[0,0], bounds[0,1]+0.1, 0.1)\n",
        "# compute values of loss function at given weights\n",
        "loss_values = loss_fn(input_w)\n",
        "# create a line plot of input vs result\n",
        "pyplot.plot(input_w, loss_values)\n",
        "# plot the solutions found\n",
        "pyplot.plot(weights_list, weights_eval_list, '.-', color='red')\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">0 L(-4.0) = 16.00000\n",
            ">1 L(-3.2) = 10.24000\n",
            ">2 L(-2.56) = 6.55360\n",
            ">3 L(-2.048) = 4.19430\n",
            ">4 L(-1.6384) = 2.68435\n",
            ">5 L(-1.31072) = 1.71799\n",
            ">6 L(-1.0485760000000002) = 1.09951\n",
            ">7 L(-0.8388608000000002) = 0.70369\n",
            ">8 L(-0.6710886400000001) = 0.45036\n",
            ">9 L(-0.5368709120000001) = 0.28823\n",
            ">10 L(-0.4294967296000001) = 0.18447\n",
            ">11 L(-0.3435973836800001) = 0.11806\n",
            ">12 L(-0.27487790694400005) = 0.07556\n",
            ">13 L(-0.21990232555520003) = 0.04836\n",
            ">14 L(-0.17592186044416003) = 0.03095\n",
            ">15 L(-0.140737488355328) = 0.01981\n",
            ">16 L(-0.11258999068426241) = 0.01268\n",
            ">17 L(-0.09007199254740993) = 0.00811\n",
            ">18 L(-0.07205759403792794) = 0.00519\n",
            ">19 L(-0.057646075230342354) = 0.00332\n",
            ">20 L(-0.04611686018427388) = 0.00213\n",
            ">21 L(-0.03689348814741911) = 0.00136\n",
            ">22 L(-0.029514790517935284) = 0.00087\n",
            ">23 L(-0.02361183241434823) = 0.00056\n",
            ">24 L(-0.018889465931478583) = 0.00036\n",
            ">25 L(-0.015111572745182867) = 0.00023\n",
            ">26 L(-0.012089258196146294) = 0.00015\n",
            ">27 L(-0.009671406556917036) = 0.00009\n",
            ">28 L(-0.007737125245533628) = 0.00006\n",
            ">29 L(-0.006189700196426903) = 0.00004\n",
            ">30 L(-0.004951760157141522) = 0.00002\n",
            ">31 L(-0.003961408125713218) = 0.00002\n",
            ">32 L(-0.0031691265005705745) = 0.00001\n",
            ">33 L(-0.00253530120045646) = 0.00001\n",
            ">34 L(-0.0020282409603651678) = 0.00000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}